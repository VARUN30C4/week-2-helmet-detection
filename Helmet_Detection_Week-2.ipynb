{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6de98e",
   "metadata": {},
   "source": [
    "# ü™ñ Helmet Detection for Bike Riders ‚Äî Week 2\n",
    "\n",
    "### üéØ Objective (Week 2)\n",
    "- Prepare a **custom 2-class dataset**: `helmet` and `no-helmet`\n",
    "- **Fine-tune YOLOv8** on this dataset\n",
    "- Evaluate with **precision/recall, mAP** and confusion matrix\n",
    "- Run **batch inference** on images & videos\n",
    "- Optional: **real-time webcam demo**\n",
    "- Export model to **ONNX/TFLite** for deployment\n",
    "\n",
    "> This notebook assumes you either:\n",
    "> 1) Have a local dataset in YOLO format (recommended), or\n",
    "> 2) Will download one via Roboflow (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2868a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Ultralytics: 8.3.223\n",
      "OpenCV: 4.12.0\n",
      "Matplotlib: 3.10.7\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) Install dependencies\n",
    "# ------------------------------------------------------------\n",
    "!pip install -q ultralytics opencv-python matplotlib ipywidgets\n",
    "\n",
    "import sys, ultralytics, cv2, matplotlib\n",
    "print(\"Python:\", sys.version.split(\"\\n\")[0])\n",
    "print(\"Ultralytics:\", ultralytics.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a7da5-b190-4ecc-9bba-5393f620bdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e1188-905f-4e39-845b-034b25da7b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc335d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\varun kumar\n",
      "Data directory: C:\\Users\\varun kumar\\data_week2\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2) Imports & paths\n",
    "# ------------------------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "import os, yaml\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "DATA_DIR = ROOT / \"data_week2\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Expected structure if you have a local dataset in YOLO format:\n",
    "# data_week2/\n",
    "#   ‚îú‚îÄ‚îÄ images/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ train/*.jpg|png\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ val/*.jpg|png\n",
    "#   ‚îú‚îÄ‚îÄ labels/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ train/*.txt\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ val/*.txt\n",
    "#   ‚îî‚îÄ‚îÄ data.yaml  (we will create if missing)\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "print(\"Data directory:\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5237c6",
   "metadata": {},
   "source": [
    "## Option A ‚Äî Use **local dataset** (recommended)\n",
    "Place your dataset in `data_week2/images` and `data_week2/labels` (YOLO format). Then run the cell below to create `data.yaml` automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600da354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wrote: C:\\Users\\varun kumar\\data_week2\\data.yaml\n",
      "names:\n",
      "- helmet\n",
      "- no-helmet\n",
      "path: C:\\Users\\varun kumar\\data_week2\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "Ensured: C:\\Users\\varun kumar\\data_week2\\images\\train\n",
      "Ensured: C:\\Users\\varun kumar\\data_week2\\images\\val\n",
      "Ensured: C:\\Users\\varun kumar\\data_week2\\labels\\train\n",
      "Ensured: C:\\Users\\varun kumar\\data_week2\\labels\\val\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3A) Create data.yaml for LOCAL dataset (2 classes)\n",
    "# ------------------------------------------------------------\n",
    "images_train = DATA_DIR / \"images\" / \"train\"\n",
    "images_val   = DATA_DIR / \"images\" / \"val\"\n",
    "labels_train = DATA_DIR / \"labels\" / \"train\"\n",
    "labels_val   = DATA_DIR / \"labels\" / \"val\"\n",
    "\n",
    "yaml_path = DATA_DIR / \"data.yaml\"\n",
    "data_cfg = {\n",
    "    'path': str(DATA_DIR.resolve()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': ['helmet', 'no-helmet']\n",
    "}\n",
    "\n",
    "yaml_path.write_text(yaml.dump(data_cfg))\n",
    "print(\"‚úÖ Wrote:\", yaml_path)\n",
    "print(yaml_path.read_text())\n",
    "\n",
    "for p in [images_train, images_val, labels_train, labels_val]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Ensured:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957b93a",
   "metadata": {},
   "source": [
    "## Option B ‚Äî Download a dataset from Roboflow (optional)\n",
    "1. Create a free Roboflow account and get an API key\n",
    "2. Replace `YOUR_API_KEY` and `WORKSPACE/PROJECT:VERSION`\n",
    "3. Run the cell to auto-download in YOLOv8 format\n",
    "\n",
    "_Skip if you already have a local dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955f3117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Roboflow download. Using local dataset.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3B) (Optional) Roboflow download to data_week2/\n",
    "# ------------------------------------------------------------\n",
    "use_roboflow = False  # set True after adding your API key & project\n",
    "if use_roboflow:\n",
    "    !pip install -q roboflow\n",
    "    from roboflow import Roboflow\n",
    "    rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "    project = rf.workspace(\"WORKSPACE\").project(\"PROJECT\")\n",
    "    dataset = project.version(VERSION_NUMBER).download(\"yolov8\", location=str(DATA_DIR))\n",
    "    print(\"Downloaded to:\", dataset.location)\n",
    "    # If roboflow creates its own folder, copy/move data.yaml up to data_week2/data.yaml if needed\n",
    "else:\n",
    "    print(\"Skipping Roboflow download. Using local dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe6904",
   "metadata": {},
   "source": [
    "## Quick dataset sanity check\n",
    "- Counts images and labels\n",
    "- Warns about potential missing labels\n",
    "- Shows a couple of sample images if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e522ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 0 | labels: 0\n",
      "Val images  : 0 | labels: 0\n",
      "‚ö†Ô∏è Add images to data_week2/images/train and images/val before training.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "def count_files(folder, exts=(\".jpg\", \".jpeg\", \".png\")):\n",
    "    return sum(1 for p in Path(folder).rglob(\"*\") if p.suffix.lower() in exts)\n",
    "\n",
    "n_train_img = count_files(images_train)\n",
    "n_val_img   = count_files(images_val)\n",
    "n_train_lab = len(list(labels_train.rglob(\"*.txt\")))\n",
    "n_val_lab   = len(list(labels_val.rglob(\"*.txt\")))\n",
    "\n",
    "print(f\"Train images: {n_train_img} | labels: {n_train_lab}\")\n",
    "print(f\"Val images  : {n_val_img} | labels: {n_val_lab}\")\n",
    "if n_train_img == 0 or n_val_img == 0:\n",
    "    print(\"‚ö†Ô∏è Add images to data_week2/images/train and images/val before training.\")\n",
    "\n",
    "# Show a couple of samples if available\n",
    "sample_paths = list(Path(images_train).rglob(\"*.jpg\")) + list(Path(images_train).rglob(\"*.png\"))\n",
    "random.shuffle(sample_paths)\n",
    "for p in sample_paths[:2]:\n",
    "    import cv2, matplotlib.pyplot as plt\n",
    "    img = cv2.imread(str(p))\n",
    "    if img is None: continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.imshow(img)\n",
    "    plt.title(p.name)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a01f3",
   "metadata": {},
   "source": [
    "## Train ‚Äî Fine-tune YOLOv8n on 2 classes\n",
    "You can tweak `epochs`, `imgsz`, `batch`, and `lr0`. Early stopping via `patience`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93939e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.226 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.223  Python-3.13.7 torch-2.9.0+cpu CPU (13th Gen Intel Core i7-1360P)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/varun kumar/Downloads/Motorcycle Helmet Detection.v2i.yolov8/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=helmet_yolov8n3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_week2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\varun kumar\\runs_week2\\helmet_yolov8n3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 795.2276.9 MB/s, size: 63.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\varun kumar\\Downloads\\Motorcycle Helmet Detection.v2i.yolov8\\train\\labels.cache... 1272 images, 30 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1272/1272 2.6Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 600.7244.3 MB/s, size: 55.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\varun kumar\\Downloads\\Motorcycle Helmet Detection.v2i.yolov8\\valid\\labels.cache... 121 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 121/121 133.2Kit/s 0.0s\n",
      "Plotting labels to C:\\Users\\varun kumar\\runs_week2\\helmet_yolov8n3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\varun kumar\\runs_week2\\helmet_yolov8n3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.409      3.232      1.747         74        640: 6% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5/80 0.2it/s 27.7s<6:468"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Training (with your real dataset)\n",
    "# ------------------------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the pretrained YOLOv8n model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train using your downloaded dataset\n",
    "results = model.train(\n",
    "    data=\"C:/Users/varun kumar/Downloads/Motorcycle Helmet Detection.v2i.yolov8/data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=10,\n",
    "    lr0=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    project=\"runs_week2\",\n",
    "    name=\"helmet_yolov8n\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete. Best weights saved to:\", model.trainer.best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ebf0e",
   "metadata": {},
   "source": [
    "## Validate ‚Äî Metrics & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df571688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5) Validation on the best weights\n",
    "# ------------------------------------------------------------\n",
    "best_weights = Path(model.trainer.best)\n",
    "best_model = YOLO(str(best_weights))\n",
    "metrics = best_model.val(data=str(yaml_path), imgsz=640, batch=16)\n",
    "print(metrics)  # shows mAP50-95, precision, recall, etc.\n",
    "\n",
    "# Display confusion matrix if generated\n",
    "conf_mat = best_model.ckpt_path and (best_weights.parent / \"confusion_matrix.png\")\n",
    "cm_candidates = list(best_weights.parent.rglob(\"confusion_matrix.png\"))\n",
    "if cm_candidates:\n",
    "    from IPython.display import Image\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(Image(filename=str(cm_candidates[0])))\n",
    "else:\n",
    "    print(\"(Confusion matrix image not found in run folder.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e358e",
   "metadata": {},
   "source": [
    "## Inference ‚Äî Batch on a folder of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6) Batch inference on any images folder\n",
    "# ------------------------------------------------------------\n",
    "INFER_DIR = ROOT / \"demo_images\"\n",
    "INFER_DIR.mkdir(exist_ok=True)\n",
    "print(\"Put some .jpg/.png images into:\", INFER_DIR)\n",
    "\n",
    "pred = best_model.predict(source=str(INFER_DIR), save=True, imgsz=640, conf=0.25)\n",
    "print(\"Saved predictions to:\", pred[0].save_dir if pred else \"<none>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a877e3f",
   "metadata": {},
   "source": [
    "## Video inference ‚Äî on a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 7) Video inference on a video file\n",
    "# ------------------------------------------------------------\n",
    "VIDEO_PATH = str((ROOT / \"sample.mp4\").resolve())  # change to your path\n",
    "if Path(VIDEO_PATH).exists():\n",
    "    _ = best_model.predict(source=VIDEO_PATH, save=True, imgsz=640, conf=0.25)\n",
    "else:\n",
    "    print(\"No video found at:\", VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd8147",
   "metadata": {},
   "source": [
    "## Real-time webcam demo (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f873af3",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 8) Webcam demo (press 'q' to quit)\n",
    "# ------------------------------------------------------------\n",
    "import cv2\n",
    "\n",
    "def show_webcam(model, cam_index=0, conf=0.25):\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ö†Ô∏è Could not open webcam.\")\n",
    "        return\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "            results = model.predict(frame, imgsz=640, conf=conf, verbose=False)\n",
    "            annotated = results[0].plot()\n",
    "            cv2.imshow(\"Helmet Detection (q to quit)\", annotated)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Uncomment to run locally\n",
    "# show_webcam(best_model, cam_index=0, conf=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787d3b7",
   "metadata": {},
   "source": [
    "## Export model ‚Äî ONNX/TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 9) Export formats\n",
    "# ------------------------------------------------------------\n",
    "onnx_path = best_model.export(format=\"onnx\")\n",
    "print(\"Exported ONNX:\", onnx_path)\n",
    "\n",
    "try:\n",
    "    tflite_path = best_model.export(format=\"tflite\")\n",
    "    print(\"Exported TFLite:\", tflite_path)\n",
    "except Exception as e:\n",
    "    print(\"TFLite export not available in this environment:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03183c03",
   "metadata": {},
   "source": [
    "---\n",
    "### üß† GitHub README (Week 2)\n",
    "```markdown\n",
    "# Helmet Detection ‚Äî Week 2\n",
    "\n",
    "## Goals\n",
    "- Fine-tune YOLOv8 for 2 classes: `helmet`, `no-helmet`\n",
    "- Evaluate (mAP, P/R) and confusion matrix\n",
    "- Image/Video/Real-time inference\n",
    "- Export to ONNX/TFLite\n",
    "\n",
    "## Dataset (YOLO format)\n",
    "data_week2/\n",
    "  ‚îú‚îÄ‚îÄ images/{train,val}\n",
    "  ‚îú‚îÄ‚îÄ labels/{train,val}\n",
    "  ‚îî‚îÄ‚îÄ data.yaml\n",
    "\n",
    "## Train\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data='data_week2/data.yaml', epochs=50, imgsz=640)\n",
    "```\n",
    "\n",
    "## Inference\n",
    "```python\n",
    "best = YOLO('runs_week2/helmet_yolov8n/weights/best.pt')\n",
    "best.predict('demo_images', save=True)\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900d4487-e5d5-40eb-a744-005dfc50028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun kumar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e943043-27b3-446a-abbb-5d63a6ab3841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
